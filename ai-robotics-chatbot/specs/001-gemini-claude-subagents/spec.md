# Feature Specification: Multi-Provider LLM & Subagent Framework

**Feature Branch**: `001-gemini-claude-subagents`  
**Created**: 2025-12-07  
**Status**: Active Implementation  
**Input**: User request to integrate Google Gemini API and Anthropic Claude with subagent support

## Feature Overview

Enable the AI Robotics Chatbot to support multiple LLM providers (OpenAI, Google Gemini, Anthropic Claude) with a pluggable subagent framework for specialized tasks (document search, code generation, citation handling).

### Goals
1. Support Gemini API as a primary LLM provider for chat responses and embeddings
2. Support Claude API for advanced reasoning and multi-turn conversations
3. Implement a subagent framework that allows specialized agents to handle different task types
4. Maintain backward compatibility with existing OpenAI integration
5. Provide graceful fallbacks when external APIs fail

## User Scenarios & Testing

### Scenario 1: User Selects Gemini Provider (Priority: P1)

A developer sets `LLM_PROVIDER=google` and `GEMINI_API_KEY=...` in `.env` and starts the backend. When posting a chat query, the response should be generated via Google Generative AI.

**Acceptance Criteria**:
- Backend starts without error
- `/api/health` confirms Gemini is configured
- `/api/chat/query` returns a valid response (fallback if Gemini fails)
- Response includes `model: "gemini-pro"` or similar

### Scenario 2: User Selects Claude Provider (Priority: P1)

A developer sets `LLM_PROVIDER=claude` and `CLAUDE_API_KEY=...` in `.env`. When posting a chat query, the response should be generated via Anthropic Claude.

**Acceptance Criteria**:
- Backend starts without error
- `/api/health` confirms Claude is configured
- `/api/chat/query` returns a valid response generated by Claude
- Multi-turn conversation history is preserved

### Scenario 3: Invoke Subagent for Specialized Task (Priority: P2)

A user sends a query with `"use_agent": "document_search"` flag. The backend should route the request to a specialized subagent that retrieves and ranks relevant documents before generating the response.

**Acceptance Criteria**:
- Request succeeds with `200 OK`
- Response includes `retrieved_documents` with ranked relevance scores
- Response includes `agent_used: "document_search"`

### Scenario 4: Fallback Behavior (Priority: P1)

If the configured LLM provider fails (e.g., API quota exceeded), the system should fallback to the built-in knowledge base and return a reasonable response.

**Acceptance Criteria**:
- No 500 errors; response is `200 OK` with fallback content
- Response includes a note: "Fallback response (provider unavailable)"

## Requirements

### Functional Requirements

- **FR-001**: Support `LLM_PROVIDER` configuration with values: `openai`, `google`, `claude`
- **FR-002**: When `LLM_PROVIDER=google`, use Google Generative AI client for chat responses
- **FR-003**: When `LLM_PROVIDER=claude`, use Anthropic Claude client for chat responses
- **FR-004**: `app/llm_service.py` MUST include adapters for Gemini and Claude
- **FR-005**: `app/agents.py` MUST implement a subagent registry and dispatcher
- **FR-006**: Support at least 3 subagents: `document_search`, `code_agent`, `citation_agent`
- **FR-007**: `/api/chat/query` MUST accept optional `use_agent` field to invoke subagents
- **FR-008**: All providers MUST include fallback logic when APIs fail
- **FR-009**: `/api/health` MUST report which LLM provider is active

### Non-Functional Requirements

- **NFR-001**: Response latency MUST be < 5 seconds for Gemini/Claude calls
- **NFR-002**: All provider calls MUST include retry logic (up to 3 attempts)
- **NFR-003**: Fallback responses MUST be returned within 100ms
- **NFR-004**: Code MUST be testable (no external dependencies in constructor)

## Key Entities

- **LLMProvider**: Abstract interface for OpenAI, Gemini, Claude
- **Subagent**: Represents a specialized agent (document_search, code_agent, etc.)
- **SubagentRegistry**: Registry of available subagents and dispatcher

## Success Criteria

- **SC-001**: All 3 LLM providers (OpenAI, Gemini, Claude) can be successfully configured and return chat responses
- **SC-002**: Subagent invocation returns correct agent_used field and agent-specific output
- **SC-003**: Fallback responses occur gracefully without 500 errors
- **SC-004**: `/api/health` correctly reports active provider and agent count
